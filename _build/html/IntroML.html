

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>6. Machine Learning &#8212; Técnicas de Machine Learning con Python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'IntroML';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="7. Aprendizaje Supervisado" href="AprendizajeSupervisado.html" />
    <link rel="prev" title="5. Pruebas de Hipótesis" href="PruebasHipotesis.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.jpg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.jpg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Machine Learning con Python
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introducción a Python</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="IntroduccionPython.html">1. Python, una introducción</a></li>
<li class="toctree-l1"><a class="reference internal" href="Pandas.html">2. Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="Visualizacion.html">3. Gráficos básicos: matplotlib &amp; seaborn</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Análisis Exploratorio de Datos</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Descriptiva.html">4. Estadística Descriptiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="PruebasHipotesis.html">5. Pruebas de Hipótesis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Aprendizaje Supervizado</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">6. Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="AprendizajeSupervisado.html">7. Aprendizaje Supervisado</a></li>
<li class="toctree-l1"><a class="reference internal" href="Regresion.html">8. Regresión lineal</a></li>
<li class="toctree-l1"><a class="reference internal" href="ProbModels.html">9. Modelos de Probabilidad</a></li>
<li class="toctree-l1"><a class="reference internal" href="StepRegularization.html">10. Selección y regularización de modelos lineales</a></li>
<li class="toctree-l1"><a class="reference internal" href="Arboles.html">11. Árboles de decisión</a></li>
<li class="toctree-l1"><a class="reference internal" href="SVM.html">12. Support Vector Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="RedesNeuronales.html">13. Redes Neuronales</a></li>
<li class="toctree-l1"><a class="reference internal" href="Evaluacion.html">14. Evaluación de Modelos</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Aprendizaje no Supervisado</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ACP.html">15. Análisis de Componentes Principales</a></li>
<li class="toctree-l1"><a class="reference internal" href="NoSupervizado.html">16. Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="ReglasAso.html">17. Minería de Reglas de asociación</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/vmoprojs/MLPython" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/vmoprojs/MLPython/issues/new?title=Issue%20on%20page%20%2FIntroML.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/IntroML.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Machine Learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#el-bosque-inteligencia-artificial">6.1. El bosque: Inteligencia Artificial</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">6.2. Machine Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#terminologia">6.2.1. Terminología</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aprendizaje-supervisado">6.3. Aprendizaje Supervisado</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimar-f">6.3.1. Estimar <span class="math notranslate nohighlight">\(f\)</span></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#prediccion">6.3.1.1. Predicción</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#error-total">6.3.1.1.1. Error Total</a><ul class="nav section-nav flex-column">
<li class="toc-h6 nav-item toc-entry"><a class="reference internal nav-link" href="#error-reducible-e-irreducible">6.3.1.1.1.1. Error Reducible e Irreducible</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#inferencia">6.3.1.2. Inferencia</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#descomposicion-de-sesgo-varianza-del-error-reducible">6.3.2. Descomposición de Sesgo-Varianza (del Error Reducible)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#en-sintesis">6.3.3. En síntesis</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metodos-de-remuestreo">6.4. Métodos de remuestreo</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bootstrap">6.4.1. Bootstrap</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation">6.5. Cross-validation</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="machine-learning">
<h1><span class="section-number">6. </span>Machine Learning<a class="headerlink" href="#machine-learning" title="Permalink to this heading">#</a></h1>
<section id="el-bosque-inteligencia-artificial">
<h2><span class="section-number">6.1. </span>El bosque: Inteligencia Artificial<a class="headerlink" href="#el-bosque-inteligencia-artificial" title="Permalink to this heading">#</a></h2>
<p>Visto en un campo más amplio, el Machine Leaning o Aprendizaje Automático es un subconjunto de la Inteligencia Aritificial.</p>
<a class="reference internal image-reference" href="_images/Diapositiva1.jpeg"><img alt="_images/Diapositiva1.jpeg" src="_images/Diapositiva1.jpeg" style="width: 700px; height: 400px;" /></a>
<p>La imagen que antecede nos muestra varios componentes de la Inteligencia Artificial (IA) donde tenemos:</p>
<ul class="simple">
<li><p><strong>Supervised Learning</strong>: Aprendizaje supervisado, se presenta en un círculo más grande puesto que es el que ha tenido más penetración en distintas aplicaciones, tanto desde la perspectiva de aplicaciones en la industria así como avances dado por la comunidad de desarrolladores y la academia. Hoy es posible hacer aprendizaje supervisado de alto nivel en un computador personal.</p></li>
<li><p><strong>Unsupervised Learning</strong>: Aprendizaje no supervisado, menos popular pero también con aplicaciones en distintas áreas.</p></li>
<li><p><strong>Reinforcement Learning</strong>: Aprendizaje por refuerzo, <em>inspirada en la psicología conductista, cuya ocupación es determinar qué acciones debe escoger un agente de software en un entorno dado con el fin de maximizar alguna noción de “recompensa” o premio acumulado</em>.</p></li>
<li><p><strong>Generative IA</strong>: Inteligencia Artificial Generativa, tiene por objetivo la generación de texto, imágenes u otros medios en respuesta a comandos.</p></li>
</ul>
<p>Es importante mencionar que la Inteligencia Artificial Generativa está teniendo un gran impacto en distintas aplicaciones, pero el desarrollo de este tipo de IA es limitado a empresas con grandes capitales. Esto se debe a que se estima que desarrollar requiere de una inversión de alrededor de USD 500 millones.</p>
</section>
<section id="id1">
<h2><span class="section-number">6.2. </span>Machine Learning<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<p>Es un conjunto amplio de herramientas para entender y descrubrir estructras en los datos. Estas herramientas se clasifican en <strong>supervisadas</strong> y <strong>no supervisadas</strong>.</p>
<a class="reference internal image-reference" href="_images/Diapositiva2.jpeg"><img alt="_images/Diapositiva2.jpeg" src="_images/Diapositiva2.jpeg" style="width: 700px; height: 400px;" /></a>
<section id="terminologia">
<h3><span class="section-number">6.2.1. </span>Terminología<a class="headerlink" href="#terminologia" title="Permalink to this heading">#</a></h3>
<p>El <strong>aprendizaje supervisado</strong> implica la construcción de un modelo estadístico para <strong>predecir</strong> o estimar un resultado en función de una o más variables de entrada. Podemos considerar el aprendizaje supervisado como el uso de una función que asigna variables de entrada a un resultado.</p>
<ul class="simple">
<li><p>Las <strong>variables de entrada</strong> tienen muchos nombres, como: x, explicativa (<em>explanatory</em>), predictora (<em>predictor</em>), regresora (<em>regressor</em>), independiente y característica (<em>feature</em>).</p></li>
<li><p>La <strong>variable de salida</strong> también tiene muchos nombres, como: y, respuesta (<em>response</em>), dependiente, objetivo (<em>target</em>), resultado y etiqueta (<em>label</em>).</p></li>
</ul>
<p>En el <strong>aprendizaje no supervisado</strong>, hay entradas pero no salidas supervisadas; no obstante, podemos aprender relaciones y estructuras a partir de esos datos. Los problemas de aprendizaje no supervisado que cubrimos se dividen en dos grandes categorías:</p>
<ul class="simple">
<li><p>La <strong>reducción de dimensionalidad</strong> es una técnica para transformar datos de alta dimensión en un espacio de baja dimensión, preservando al mismo tiempo las propiedades útiles de los datos.</p></li>
<li><p>La agrupación en <strong>clústeres</strong> o conglomerados es una técnica que implica encontrar subgrupos, o clústeres, en un conjunto de datos de modo que las observaciones dentro del mismo grupo sean bastante <em>similares</em> entre sí, mientras que las observaciones en diferentes grupos sean bastante <em>diferentes</em> entre sí.</p></li>
</ul>
</section>
</section>
<section id="aprendizaje-supervisado">
<h2><span class="section-number">6.3. </span>Aprendizaje Supervisado<a class="headerlink" href="#aprendizaje-supervisado" title="Permalink to this heading">#</a></h2>
<p>Supongamos que observas una respuesta cuantitativa <span class="math notranslate nohighlight">\(Y\)</span> y <span class="math notranslate nohighlight">\(p\)</span> predictores, <span class="math notranslate nohighlight">\(X_1,X_2,\cdots,X_p\)</span>. Deseamos estimar una relación entre <span class="math notranslate nohighlight">\(Y\)</span> y <span class="math notranslate nohighlight">\(X=(X_1,X_2,\cdots,X_p)\)</span> que puede escribirse como:</p>
<div class="math notranslate nohighlight">
\[
Y = f(X)+\epsilon
\]</div>
<p><span class="math notranslate nohighlight">\(f\)</span> es una fija de <span class="math notranslate nohighlight">\(X_1,X_2,\cdots,X_p\)</span> que no conocemos, y <span class="math notranslate nohighlight">\(\epsilon\)</span> es un término de <strong>error aleatorio</strong> que es independiente de <span class="math notranslate nohighlight">\(X\)</span> y tiene media cero. En esta fórmula, <span class="math notranslate nohighlight">\(f\)</span> representa la información sistemática que <span class="math notranslate nohighlight">\(X\)</span> provee acerca de <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>En el siguiente ejemplo, simulamos una relación entre Edad (<span class="math notranslate nohighlight">\(X\)</span>) e Ingreso (<span class="math notranslate nohighlight">\(Y\)</span>) donde</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X\in [18,65]\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(Y=f(X) = 1000log(X)+4000\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\epsilon \sim \mathcal{N}(\mu=0,\sigma=100)\)</span></p></li>
</ul>
<p>Luego truncamos los valores de Y entre 4000 y 30000 (nota que usamos <code class="docutils literal notranslate"><span class="pre">np.clip</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Generamos un rango de valores de X entre 18 y 65</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">65</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>

<span class="c1"># Definimos una función no lineal para Y (por ejemplo, una función cuadrática)</span>
<span class="n">fx</span> <span class="o">=</span> <span class="mi">1000</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">+</span> <span class="mi">4000</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">fx</span><span class="o">+</span><span class="n">epsilon</span>

<span class="c1"># Limitamos los valores de Y entre 4000 y 30000</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="mi">4000</span><span class="p">,</span> <span class="mi">30000</span><span class="p">)</span>

<span class="c1"># Graficamos la función</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Valores observados&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">fx</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Función real de la relación entre Edad e Ingreso&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X (Edad)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Y (Ingreso)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Simulación de una función entre X y Y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5b18ab8c67fa89492bcec7795a9f7c51e25530d066031e09b1c4ca7e8616bbab.png" src="_images/5b18ab8c67fa89492bcec7795a9f7c51e25530d066031e09b1c4ca7e8616bbab.png" />
</div>
</div>
<p>En esencia, el aprendizaje supervisado es un conjunto de métodos que nos ayudan a estimar <span class="math notranslate nohighlight">\(f\)</span>. Al estimar <span class="math notranslate nohighlight">\(f\)</span> aparecen conceptos teóricos con los que debemos familiarizarnos y también debemos tener herramientas que nos evaluar la estimación que hemos obtenido: <span class="math notranslate nohighlight">\(\hat{f}\)</span>.</p>
<section id="estimar-f">
<h3><span class="section-number">6.3.1. </span>Estimar <span class="math notranslate nohighlight">\(f\)</span><a class="headerlink" href="#estimar-f" title="Permalink to this heading">#</a></h3>
<p>Hay dos razones para estimar <span class="math notranslate nohighlight">\(f\)</span>: predicción e inferencia.</p>
<section id="prediccion">
<h4><span class="section-number">6.3.1.1. </span>Predicción<a class="headerlink" href="#prediccion" title="Permalink to this heading">#</a></h4>
<p>En problemas reales tenemos disponible datos de entrada <span class="math notranslate nohighlight">\(X\)</span> y sus etiquetas <span class="math notranslate nohighlight">\(Y\)</span> y deseamos estimar la relación entre <span class="math notranslate nohighlight">\(X\)</span> y <span class="math notranslate nohighlight">\(Y\)</span>, para ello:</p>
<div class="math notranslate nohighlight">
\[
\hat{Y} = \hat{f}(X)
\]</div>
<p>donde <span class="math notranslate nohighlight">\(\hat{f}\)</span> representa nuestra estimación de <span class="math notranslate nohighlight">\(f\)</span> y <span class="math notranslate nohighlight">\(\hat{Y}\)</span> representa la predicción de <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>No necesariamente debemos saber la forma funcional exacta de <span class="math notranslate nohighlight">\(\hat{f}\)</span> siempre y cuando tengamos predicciones precisas de <span class="math notranslate nohighlight">\(Y\)</span>. Cuando esto sucede, se lo conoce como un problema de <em>caja negra</em>.</p>
<section id="error-total">
<h5><span class="section-number">6.3.1.1.1. </span>Error Total<a class="headerlink" href="#error-total" title="Permalink to this heading">#</a></h5>
<p>En aprendizaje supervisado, el error total puede descomponerse en el <strong>error de predicción esperado (EPE)</strong>, que es la diferencia cuadrática esperada entre el resultado predicho <span class="math notranslate nohighlight">\(\hat{Y}\)</span> y el resultado verdadero <span class="math notranslate nohighlight">\(Y\)</span>, es decir, el error cuadrático medio (MSE):</p>
<div class="math notranslate nohighlight">
\[
EPE(X) = \mathbb{E}[(Y - \hat{Y}(X))^2]
\]</div>
<p>Donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Y\)</span> es el valor verdadero (la etiqueta).</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{Y}(X)\)</span> es la predicción del modelo en la entrada <span class="math notranslate nohighlight">\(X\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{E}[\cdot]\)</span> denota la esperanza.</p></li>
</ul>
<p>Ahora, queremos descomponer esto en componentes de <strong>error reducible</strong> y <strong>error irreducible</strong>.</p>
<section id="error-reducible-e-irreducible">
<h6><span class="section-number">6.3.1.1.1.1. </span>Error Reducible e Irreducible<a class="headerlink" href="#error-reducible-e-irreducible" title="Permalink to this heading">#</a></h6>
<p>Dado que la etiqueta <span class="math notranslate nohighlight">\(Y\)</span> se puede descomponer en una parte determinista <span class="math notranslate nohighlight">\(f(X)\)</span> y un ruido <span class="math notranslate nohighlight">\(\epsilon\)</span>, es decir:</p>
<div class="math notranslate nohighlight">
\[
Y = f(X) + \epsilon
\]</div>
<p>Donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(f(X)\)</span> es la verdadera función subyacente (que intentamos aproximar con nuestro modelo).</p></li>
<li><p><span class="math notranslate nohighlight">\(\epsilon\)</span> es un ruido aleatorio con media cero <span class="math notranslate nohighlight">\((\mathbb{E}[\epsilon] = 0\)</span>) y varianza <span class="math notranslate nohighlight">\(\sigma^2\)</span> (<span class="math notranslate nohighlight">\(\text{Var}[\epsilon] = \sigma^2\)</span>).</p></li>
</ul>
<p>El <strong>error total</strong> ahora puede descomponerse en:</p>
<div class="math notranslate nohighlight">
\[
EPE(X) = \mathbb{E}[(f(X) + \epsilon - \hat{f}(X))^2]
\]</div>
<p>Expandiendo esta expresión:</p>
<div class="math notranslate nohighlight">
\[
EPE(X) = \mathbb{E}[(f(X) - \hat{f}(X))^2] + \mathbb{E}[\epsilon^2]
\]</div>
<p>Esto se puede interpretar como:</p>
<ol class="arabic simple">
<li><p><strong>Error Reducible</strong>: El error debido a la incapacidad del modelo para aprender perfectamente la verdadera función (f(x)). Esto está representado por <span class="math notranslate nohighlight">\(\mathbb{E}[(f(X) - \hat{f}(X))^2]\)</span>.</p></li>
<li><p><strong>Error Irreducible</strong>: El error debido al ruido inherente en los datos, es decir, <span class="math notranslate nohighlight">\(\mathbb{E}[\epsilon^2] = \sigma^2\)</span>, que no se puede reducir, sin importar cuán bien el modelo aprenda la función verdadera.</p></li>
</ol>
<p>Así, el error total es:</p>
<div class="math notranslate nohighlight">
\[
EPE(X) = \underbrace{\mathbb{E}[(f(X) - \hat{f}(X))^2]}_{\text{Error Reducible}} + \underbrace{\sigma^2}_{\text{Error Irreducible}}
\]</div>
</section>
</section>
</section>
<section id="inferencia">
<h4><span class="section-number">6.3.1.2. </span>Inferencia<a class="headerlink" href="#inferencia" title="Permalink to this heading">#</a></h4>
<p>Cuando estamos interesados en entender la asociación entre <span class="math notranslate nohighlight">\(Y\)</span> y <span class="math notranslate nohighlight">\(X_1,X_2,\cdots,X_p\)</span>, la estimación de <span class="math notranslate nohighlight">\(f\)</span>, <span class="math notranslate nohighlight">\(\hat{f}\)</span> no puede ser tratado como una caja negra. Nuestro objetivo no es necesariamente hacer predicciones de <span class="math notranslate nohighlight">\(Y\)</span>, sino que necesitamos tener una forma exacta de <span class="math notranslate nohighlight">\(f\)</span>.</p>
<p>Podemos estar interesados en responder a preguntas como:</p>
<ul class="simple">
<li><p>¿Qué predictores se asocian con la respuesta?</p></li>
<li><p>¿Cuál es la relación entre la respuesta y cada predictor?</p></li>
<li><p>¿Puede la relación entre <span class="math notranslate nohighlight">\(Y\)</span> y cada predictor ser lineal o es más sofisticada?</p></li>
</ul>
<p>Dependiendo de si nuestro objetivo final es predicción, inferencia o una combinación de ambas, pueden ser apropiados distintos métodos para estimar <span class="math notranslate nohighlight">\(f\)</span>.</p>
<p>Por ejemplo, los modelos lineales permiten una inferencia relativamente simple e interpretable, pero pueden no producir predicciones tan precisas como algunos otros enfoques de modelos lineales. Por el contrario, algunos de los enfoques altamente no lineales pueden proporcionar predicciones bastante precisas para <span class="math notranslate nohighlight">\(Y\)</span> , pero esto se produce a expensas de un modelo menos interpretable para el cual la inferencia es más desafiante.</p>
</section>
</section>
<section id="descomposicion-de-sesgo-varianza-del-error-reducible">
<h3><span class="section-number">6.3.2. </span>Descomposición de Sesgo-Varianza (del Error Reducible)<a class="headerlink" href="#descomposicion-de-sesgo-varianza-del-error-reducible" title="Permalink to this heading">#</a></h3>
<p>El error reducible se puede descomponer aún más en <strong>sesgo</strong> y <strong>varianza</strong>:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[(f(X) - \hat{f}(X))^2] = (\mathbb{E}[\hat{f}(X)] - f(x))^2 + \mathbb{E}[(\hat{f}(X) - \mathbb{E}[\hat{f}(X)])^2]
\]</div>
<p>Donde:</p>
<ul class="simple">
<li><p><strong>Sesgo</strong>: <span class="math notranslate nohighlight">\((\mathbb{E}[\hat{f}(X)] - f(X))^2\)</span> es el error debido a las suposiciones del modelo que le impiden capturar perfectamente la función verdadera.</p></li>
<li><p><strong>Varianza</strong>: <span class="math notranslate nohighlight">\(\mathbb{E}[(\hat{f}(X) - \mathbb{E}[\hat{f}(X)])^2]\)</span> es el error debido a la sensibilidad del modelo a diferentes conjuntos de datos de entrenamiento (es decir, cuánto varían las predicciones del modelo).</p></li>
</ul>
<p>Así, el error total se puede escribir como:</p>
<div class="math notranslate nohighlight">
\[
EPE(x) = \underbrace{\text{Sesgo}^2 + \text{Varianza}}_{\text{Error Reducible}} + \underbrace{\sigma^2}_{\text{Error Irreducible}}
\]</div>
</section>
<section id="en-sintesis">
<h3><span class="section-number">6.3.3. </span>En síntesis<a class="headerlink" href="#en-sintesis" title="Permalink to this heading">#</a></h3>
<ul>
<li><p><strong>Error Reducible</strong>: Esta es la parte del error que se puede reducir mejorando el modelo (por ejemplo, usando un modelo más complejo, mejor ajuste o más datos). Consiste en <strong>Sesgo</strong> y <strong>Varianza</strong>.</p>
<div class="math notranslate nohighlight">
\[
  \text{Error Reducible} = \text{Sesgo}^2 + \text{Varianza}
  \]</div>
</li>
<li><p><strong>Error Irreducible</strong>: Este es el ruido en los datos, que no se puede eliminar con ningún modelo. Está representado por la varianza del ruido <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
<div class="math notranslate nohighlight">
\[
  \text{Error Irreducible} = \sigma^2
  \]</div>
</li>
</ul>
<p>Por lo tanto, la fórmula general para el error de predicción esperado (error total) es:</p>
<div class="math notranslate nohighlight">
\[
EPE(x) = \text{Sesgo}^2 + \text{Varianza} + \sigma^2
\]</div>
</section>
</section>
<section id="metodos-de-remuestreo">
<h2><span class="section-number">6.4. </span>Métodos de remuestreo<a class="headerlink" href="#metodos-de-remuestreo" title="Permalink to this heading">#</a></h2>
<p>Los <strong>métodos de remuestreo</strong> son una herramienta indispensable en la estadística moderna. Implican extraer repetidamente muestras de un conjunto de <strong>entrenamiento</strong> y reajustar un modelo de interés en cada muestra para obtener información adicional sobre el modelo ajustado.</p>
<p>Dos métodos más usados en el remuestreo son <em>bootstrap</em> y <em>cross-validation</em>.</p>
<p><strong>Bootstrap</strong></p>
<p>El bootstrap se utiliza en varios contextos, más comúnmente para proporcionar una <strong>medida de precisión</strong> de una estimación de un parámetro o de un método de aprendizaje estadístico dado.</p>
<p><strong>Cross-validation</strong></p>
<p>El proceso de evaluar el desempeño de un modelo se conoce como <strong>evaluación del modelo</strong>, mientras que el proceso de seleccionar el nivel adecuado de flexibilidad para un modelo se conoce como <strong>selección del modelo</strong>.</p>
<section id="bootstrap">
<h3><span class="section-number">6.4.1. </span>Bootstrap<a class="headerlink" href="#bootstrap" title="Permalink to this heading">#</a></h3>
<p>Supongamos que deseamos obtener el siguiente estimador</p>
<div class="math notranslate nohighlight">
\[
\tau = \frac{\text{median}(x)}{(\text{max}(x)-\text{min}(x))}
\]</div>
<p>Nota que, si el problema fuese estimar el <a class="reference external" href="https://es.wikipedia.org/wiki/Intervalo_de_confianza">intervalo de confianza de la media</a>, tenemos un procedimiento paramétrico para hacerlo (pero también podemos usar bootstrap). Sin embargo, el estimador <span class="math notranslate nohighlight">\(\tau\)</span> no tiene un fórmula específica para estimar los intervalos de confianza, estos son los ejemplos donde bootstrap es más útil.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="n">edad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">24</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">26</span><span class="p">,</span><span class="mi">27</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">29</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">31</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">38</span><span class="p">,</span><span class="mi">48</span><span class="p">])</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">edad</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># tamaño de la población</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">19</span><span class="p">)</span>
<span class="n">indice</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">n</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># posiciones de la población (id)</span>
<span class="n">nsam</span> <span class="o">=</span> <span class="mi">20</span> <span class="c1"># Tamaño de la muestra (generalmente es igual a n)</span>
<span class="n">sam</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choices</span><span class="p">(</span><span class="n">indice</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">nsam</span><span class="p">)</span> <span class="c1"># Tomamos una muestra con reemplazo</span>
<span class="n">tau</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">edad</span><span class="p">[</span><span class="n">sam</span><span class="p">])</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">ptp</span><span class="p">(</span><span class="n">edad</span><span class="p">[</span><span class="n">sam</span><span class="p">])</span>
<span class="n">tau</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.125
</pre></div>
</div>
</div>
</div>
<p>A mano</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">tau_f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">ptp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span>

<span class="n">nboot</span> <span class="o">=</span> <span class="mi">9999</span>
<span class="n">tau_sol</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">nboot</span><span class="p">):</span>
    <span class="n">sam</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choices</span><span class="p">(</span><span class="n">indice</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">nsam</span><span class="p">)</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="n">tau_f</span><span class="p">(</span><span class="n">edad</span><span class="p">[</span><span class="n">sam</span><span class="p">])</span>
    <span class="n">tau_sol</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>
    
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">tau_sol</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: ylabel=&#39;Count&#39;&gt;
</pre></div>
</div>
<img alt="_images/3de6534ca707da05f3b170da868ae043b94d1ce4f4ad27a84bb2d401f198166b.png" src="_images/3de6534ca707da05f3b170da868ae043b94d1ce4f4ad27a84bb2d401f198166b.png" />
</div>
</div>
<p>Usando <code class="docutils literal notranslate"><span class="pre">bootstrap</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">bootstrap</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">bootstrap</span><span class="p">((</span><span class="n">edad</span><span class="p">,),</span> <span class="n">tau_f</span><span class="p">,</span> <span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="n">res</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">bootstrap_distribution</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: ylabel=&#39;Count&#39;&gt;
</pre></div>
</div>
<img alt="_images/b5840064d78e15d319c253830390da99f6e95196f1cdf6c8bdebace7781ae5fd.png" src="_images/b5840064d78e15d319c253830390da99f6e95196f1cdf6c8bdebace7781ae5fd.png" />
</div>
</div>
</section>
</section>
<section id="cross-validation">
<h2><span class="section-number">6.5. </span>Cross-validation<a class="headerlink" href="#cross-validation" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">uu</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/vmoprojs/DataLectures/master/Mundo.csv&quot;</span>

<span class="n">datos</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">uu</span><span class="p">,</span><span class="n">sep</span> <span class="o">=</span> <span class="s2">&quot;;&quot;</span><span class="p">)</span>
<span class="n">datos</span> <span class="o">=</span> <span class="n">datos</span><span class="p">[[</span><span class="s2">&quot;PNB_PC&quot;</span><span class="p">,</span><span class="s2">&quot;calorias&quot;</span><span class="p">,</span><span class="s2">&quot;exp_vida&quot;</span><span class="p">]]</span>
<span class="n">datos</span> <span class="o">=</span> <span class="n">datos</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datos</span><span class="p">[[</span><span class="s2">&quot;PNB_PC&quot;</span><span class="p">,</span><span class="s2">&quot;calorias&quot;</span><span class="p">]],</span><span class="n">datos</span><span class="o">.</span><span class="n">exp_vida</span>

<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>



<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span>
<span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span> <span class="c1">#sol</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">scores</span>




<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>
<span class="c1"># https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter</span>
<span class="n">scoring</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;r2&#39;</span><span class="p">,</span> <span class="s1">&#39;neg_mean_absolute_error&#39;</span><span class="p">]</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">)</span>
<span class="n">scores</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;fit_time&#39;: array([0.00149107, 0.00173116, 0.00155115, 0.00156879, 0.00153089]),
 &#39;score_time&#39;: array([0.00168085, 0.00169611, 0.00161576, 0.00161099, 0.00161099]),
 &#39;test_r2&#39;: array([-0.84695129,  0.28360126, -0.90154176,  0.6867929 , -5.11490281]),
 &#39;test_neg_mean_absolute_error&#39;: array([-7.59750607, -7.74954156, -9.29418544, -4.25742205, -3.78002062])}
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="PruebasHipotesis.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">5. </span>Pruebas de Hipótesis</p>
      </div>
    </a>
    <a class="right-next"
       href="AprendizajeSupervisado.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">7. </span>Aprendizaje Supervisado</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#el-bosque-inteligencia-artificial">6.1. El bosque: Inteligencia Artificial</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">6.2. Machine Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#terminologia">6.2.1. Terminología</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aprendizaje-supervisado">6.3. Aprendizaje Supervisado</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimar-f">6.3.1. Estimar <span class="math notranslate nohighlight">\(f\)</span></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#prediccion">6.3.1.1. Predicción</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#error-total">6.3.1.1.1. Error Total</a><ul class="nav section-nav flex-column">
<li class="toc-h6 nav-item toc-entry"><a class="reference internal nav-link" href="#error-reducible-e-irreducible">6.3.1.1.1.1. Error Reducible e Irreducible</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#inferencia">6.3.1.2. Inferencia</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#descomposicion-de-sesgo-varianza-del-error-reducible">6.3.2. Descomposición de Sesgo-Varianza (del Error Reducible)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#en-sintesis">6.3.3. En síntesis</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metodos-de-remuestreo">6.4. Métodos de remuestreo</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bootstrap">6.4.1. Bootstrap</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation">6.5. Cross-validation</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            <div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Víctor Morales Oñate
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div></div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>