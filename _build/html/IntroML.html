
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>6. Machine Learning &#8212; Técnicas de Machine Learning con Python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'IntroML';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="7. Aprendizaje Supervisado" href="AprendizajeSupervisado.html" />
    <link rel="prev" title="5. Pruebas de Hipótesis" href="PruebasHipotesis.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.jpg" class="logo__image only-light" alt="Técnicas de Machine Learning con Python - Home"/>
    <script>document.write(`<img src="_static/logo.jpg" class="logo__image only-dark" alt="Técnicas de Machine Learning con Python - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Machine Learning con Python
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introducción a Python</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="IntroduccionPython.html">1. Python, una introducción</a></li>
<li class="toctree-l1"><a class="reference internal" href="Pandas.html">2. Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="Visualizacion.html">3. Gráficos básicos: matplotlib &amp; seaborn</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Análisis Exploratorio de Datos</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Descriptiva.html">4. Estadística Descriptiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="PruebasHipotesis.html">5. Pruebas de Hipótesis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Aprendizaje Supervizado</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">6. Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="AprendizajeSupervisado.html">7. Aprendizaje Supervisado</a></li>
<li class="toctree-l1"><a class="reference internal" href="Regresion.html">8. Regresión lineal</a></li>
<li class="toctree-l1"><a class="reference internal" href="ProbModels.html">9. Modelos de Probabilidad</a></li>
<li class="toctree-l1"><a class="reference internal" href="StepRegularization.html">10. Selección y regularización de modelos lineales</a></li>
<li class="toctree-l1"><a class="reference internal" href="Arboles.html">11. Árboles de decisión</a></li>
<li class="toctree-l1"><a class="reference internal" href="SVM.html">12. Support Vector Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="RedesNeuronales.html">13. Redes Neuronales</a></li>
<li class="toctree-l1"><a class="reference internal" href="Evaluacion.html">14. Evaluación de Modelos</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Aprendizaje no Supervisado</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ACP.html">15. Análisis de Componentes Principales</a></li>
<li class="toctree-l1"><a class="reference internal" href="NoSupervizado.html">16. Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="ReglasAso.html">17. Minería de Reglas de asociación</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/vmoprojs/MLPython" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/vmoprojs/MLPython/issues/new?title=Issue%20on%20page%20%2FIntroML.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/IntroML.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Machine Learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#el-bosque-inteligencia-artificial">6.1. El bosque: Inteligencia Artificial</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">6.2. Machine Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#terminologia">6.2.1. Terminología</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aprendizaje-supervisado">6.3. Aprendizaje Supervisado</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimar-f">6.3.1. Estimar <span class="math notranslate nohighlight">\(f\)</span></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#prediccion">6.3.1.1. Predicción</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#error-total">6.3.1.1.1. Error Total</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#inferencia">6.3.1.2. Inferencia</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#descomposicion-de-sesgo-varianza-del-error-reducible">6.3.2. Descomposición de Sesgo-Varianza (del Error Reducible)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metodos-de-remuestreo">6.4. Métodos de remuestreo</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bootstrap">6.4.1. Bootstrap</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation">6.5. Cross-validation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parametros-del-modelo-entrenables">6.5.1. 1. Parámetros del modelo (entrenables)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hiperparametros-no-entrenables">6.5.2. 2. Hiperparámetros (no entrenables)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ejercicios">6.6. Ejercicios</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="machine-learning">
<h1><span class="section-number">6. </span>Machine Learning<a class="headerlink" href="#machine-learning" title="Link to this heading">#</a></h1>
<section id="el-bosque-inteligencia-artificial">
<h2><span class="section-number">6.1. </span>El bosque: Inteligencia Artificial<a class="headerlink" href="#el-bosque-inteligencia-artificial" title="Link to this heading">#</a></h2>
<p>Visto en un campo más amplio, el Machine Leaning o Aprendizaje Automático es un subconjunto de la Inteligencia Aritificial.</p>
<a class="reference internal image-reference" href="_images/Diapositiva1.jpeg"><img alt="_images/Diapositiva1.jpeg" src="_images/Diapositiva1.jpeg" style="width: 700px; height: 400px;" />
</a>
<p>La imagen que antecede nos muestra varios componentes de la Inteligencia Artificial (IA) donde tenemos:</p>
<ul class="simple">
<li><p><strong>Supervised Learning</strong>: Aprendizaje supervisado, se presenta en un círculo más grande puesto que es el que ha tenido más penetración en distintas aplicaciones, tanto desde la perspectiva de aplicaciones en la industria así como avances dado por la comunidad de desarrolladores y la academia. Hoy es posible hacer aprendizaje supervisado de alto nivel en un computador personal.</p></li>
<li><p><strong>Unsupervised Learning</strong>: Aprendizaje no supervisado, menos popular pero también con aplicaciones en distintas áreas.</p></li>
<li><p><strong>Reinforcement Learning</strong>: Aprendizaje por refuerzo, <em>inspirada en la psicología conductista, cuya ocupación es determinar qué acciones debe escoger un agente de software en un entorno dado con el fin de maximizar alguna noción de “recompensa” o premio acumulado</em>.</p></li>
<li><p><strong>Generative IA</strong>: Inteligencia Artificial Generativa, tiene por objetivo la generación de texto, imágenes u otros medios en respuesta a comandos.</p></li>
</ul>
<p>Es importante mencionar que la Inteligencia Artificial Generativa está teniendo un gran impacto en distintas aplicaciones, pero el desarrollo de este tipo de IA es limitado a empresas con grandes capitales. Esto se debe a que se estima que desarrollar requiere de una inversión de alrededor de USD 500 millones.</p>
</section>
<section id="id1">
<h2><span class="section-number">6.2. </span>Machine Learning<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>Es un conjunto amplio de herramientas para entender y descrubrir estructras en los datos. Estas herramientas se clasifican en <strong>supervisadas</strong> y <strong>no supervisadas</strong>.</p>
<a class="reference internal image-reference" href="_images/Diapositiva2.jpeg"><img alt="_images/Diapositiva2.jpeg" src="_images/Diapositiva2.jpeg" style="width: 700px; height: 400px;" />
</a>
<section id="terminologia">
<h3><span class="section-number">6.2.1. </span>Terminología<a class="headerlink" href="#terminologia" title="Link to this heading">#</a></h3>
<p>El <strong>aprendizaje supervisado</strong> implica la construcción de un modelo estadístico para <strong>predecir</strong> o estimar un resultado en función de una o más variables de entrada. Podemos considerar el aprendizaje supervisado como el uso de una función que asigna variables de entrada a un resultado.</p>
<ul class="simple">
<li><p>Las <strong>variables de entrada</strong> tienen muchos nombres, como: x, explicativa (<em>explanatory</em>), predictora (<em>predictor</em>), regresora (<em>regressor</em>), independiente y característica (<em>feature</em>).</p></li>
<li><p>La <strong>variable de salida</strong> también tiene muchos nombres, como: y, respuesta (<em>response</em>), dependiente, objetivo (<em>target</em>), resultado y etiqueta (<em>label</em>).</p></li>
</ul>
<p>En el <strong>aprendizaje no supervisado</strong>, hay entradas pero no salidas supervisadas; no obstante, podemos aprender relaciones y estructuras a partir de esos datos. Los problemas de aprendizaje no supervisado que cubrimos se dividen en dos grandes categorías:</p>
<ul class="simple">
<li><p>La <strong>reducción de dimensionalidad</strong> es una técnica para transformar datos de alta dimensión en un espacio de baja dimensión, preservando al mismo tiempo las propiedades útiles de los datos.</p></li>
<li><p>La agrupación en <strong>clústeres</strong> o conglomerados es una técnica que implica encontrar subgrupos, o clústeres, en un conjunto de datos de modo que las observaciones dentro del mismo grupo sean bastante <em>similares</em> entre sí, mientras que las observaciones en diferentes grupos sean bastante <em>diferentes</em> entre sí.</p></li>
</ul>
</section>
</section>
<section id="aprendizaje-supervisado">
<h2><span class="section-number">6.3. </span>Aprendizaje Supervisado<a class="headerlink" href="#aprendizaje-supervisado" title="Link to this heading">#</a></h2>
<p>Supongamos que observas una respuesta cuantitativa <span class="math notranslate nohighlight">\(Y\)</span> y <span class="math notranslate nohighlight">\(p\)</span> predictores, <span class="math notranslate nohighlight">\(X_1,X_2,\cdots,X_p\)</span>. Deseamos estimar una relación entre <span class="math notranslate nohighlight">\(Y\)</span> y <span class="math notranslate nohighlight">\(X=(X_1,X_2,\cdots,X_p)\)</span> que puede escribirse como:</p>
<div class="math notranslate nohighlight">
\[
Y = f(X)+\epsilon
\]</div>
<p><span class="math notranslate nohighlight">\(f\)</span> es una fija de <span class="math notranslate nohighlight">\(X_1,X_2,\cdots,X_p\)</span> que no conocemos, y <span class="math notranslate nohighlight">\(\epsilon\)</span> es un término de <strong>error aleatorio</strong> que es independiente de <span class="math notranslate nohighlight">\(X\)</span> y tiene media cero. En esta fórmula, <span class="math notranslate nohighlight">\(f\)</span> representa la información sistemática que <span class="math notranslate nohighlight">\(X\)</span> provee acerca de <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>En el siguiente ejemplo, simulamos una relación entre Edad (<span class="math notranslate nohighlight">\(X\)</span>) e Ingreso (<span class="math notranslate nohighlight">\(Y\)</span>) donde</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X\in [18,65]\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(Y=f(X) = 1000log(X)+4000\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\epsilon \sim \mathcal{N}(\mu=0,\sigma=100)\)</span></p></li>
</ul>
<p>Luego truncamos los valores de Y entre 4000 y 30000 (nota que usamos <code class="docutils literal notranslate"><span class="pre">np.clip</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Generamos un rango de valores de X entre 18 y 65</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">65</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>

<span class="c1"># Definimos una función no lineal para Y (por ejemplo, una función cuadrática)</span>
<span class="n">fx</span> <span class="o">=</span> <span class="mi">1000</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">+</span> <span class="mi">4000</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">fx</span><span class="o">+</span><span class="n">epsilon</span>

<span class="c1"># Limitamos los valores de Y entre 4000 y 30000</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="mi">4000</span><span class="p">,</span> <span class="mi">30000</span><span class="p">)</span>

<span class="c1"># Graficamos la función</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Valores observados&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">fx</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Función real de la relación entre Edad e Ingreso&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X (Edad)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Y (Ingreso)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Simulación de una función entre X y Y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ac4808d09c0e62466cd6df9c7f45c5fed248e60adc9ea6a736b40a7f4be2600a.png" src="_images/ac4808d09c0e62466cd6df9c7f45c5fed248e60adc9ea6a736b40a7f4be2600a.png" />
</div>
</div>
<p>En esencia, el aprendizaje supervisado es un conjunto de métodos que nos ayudan a estimar <span class="math notranslate nohighlight">\(f\)</span>. Al estimar <span class="math notranslate nohighlight">\(f\)</span> aparecen conceptos teóricos con los que debemos familiarizarnos y también debemos tener herramientas que nos evaluar la estimación que hemos obtenido: <span class="math notranslate nohighlight">\(\hat{f}\)</span>.</p>
<section id="estimar-f">
<h3><span class="section-number">6.3.1. </span>Estimar <span class="math notranslate nohighlight">\(f\)</span><a class="headerlink" href="#estimar-f" title="Link to this heading">#</a></h3>
<p>Hay dos razones para estimar <span class="math notranslate nohighlight">\(f\)</span>: predicción e inferencia.</p>
<section id="prediccion">
<h4><span class="section-number">6.3.1.1. </span>Predicción<a class="headerlink" href="#prediccion" title="Link to this heading">#</a></h4>
<p>En problemas reales tenemos disponible datos de entrada <span class="math notranslate nohighlight">\(X\)</span> y sus etiquetas <span class="math notranslate nohighlight">\(Y\)</span> y deseamos estimar la relación entre <span class="math notranslate nohighlight">\(X\)</span> y <span class="math notranslate nohighlight">\(Y\)</span>, para ello:</p>
<div class="math notranslate nohighlight">
\[
\hat{Y} = \hat{f}(X)
\]</div>
<p>donde <span class="math notranslate nohighlight">\(\hat{f}\)</span> representa nuestra estimación de <span class="math notranslate nohighlight">\(f\)</span> y <span class="math notranslate nohighlight">\(\hat{Y}\)</span> representa la predicción de <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>No necesariamente debemos saber la forma funcional exacta de <span class="math notranslate nohighlight">\(\hat{f}\)</span> siempre y cuando tengamos predicciones precisas de <span class="math notranslate nohighlight">\(Y\)</span>. Cuando esto sucede, se lo conoce como un problema de <em>caja negra</em>.</p>
<section id="error-total">
<h5><span class="section-number">6.3.1.1.1. </span>Error Total<a class="headerlink" href="#error-total" title="Link to this heading">#</a></h5>
<p>En aprendizaje supervisado, el error total puede descomponerse en el <strong>error de predicción esperado (EPE)</strong>, que es la diferencia cuadrática esperada entre el resultado predicho <span class="math notranslate nohighlight">\(\hat{Y}\)</span> y el resultado verdadero <span class="math notranslate nohighlight">\(Y\)</span>, es decir, el error cuadrático medio (MSE):</p>
<div class="math notranslate nohighlight">
\[
EPE(X) = \mathbb{E}[(Y - \hat{Y}(X))^2]
\]</div>
<p>Donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Y\)</span> es el valor verdadero (la etiqueta).</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{Y}(X)\)</span> es la predicción del modelo en la entrada <span class="math notranslate nohighlight">\(X\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{E}[\cdot]\)</span> denota la esperanza.</p></li>
</ul>
<p>Ahora, queremos descomponer esto en componentes de <strong>error reducible</strong> y <strong>error irreducible</strong>.</p>
<p><strong>Error Reducible e Irreducible</strong></p>
<p>Dado que la etiqueta <span class="math notranslate nohighlight">\(Y\)</span> se puede descomponer en una parte determinista <span class="math notranslate nohighlight">\(f(X)\)</span> y un ruido <span class="math notranslate nohighlight">\(\epsilon\)</span>, es decir:</p>
<div class="math notranslate nohighlight">
\[
Y = f(X) + \epsilon
\]</div>
<p>Donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(f(X)\)</span> es la verdadera función subyacente (que intentamos aproximar con nuestro modelo).</p></li>
<li><p><span class="math notranslate nohighlight">\(\epsilon\)</span> es un ruido aleatorio con media cero <span class="math notranslate nohighlight">\((\mathbb{E}[\epsilon] = 0\)</span>) y varianza <span class="math notranslate nohighlight">\(\sigma^2\)</span> (<span class="math notranslate nohighlight">\(\text{Var}[\epsilon] = \sigma^2\)</span>).</p></li>
</ul>
<p>El <strong>error total</strong> ahora puede descomponerse en:</p>
<div class="math notranslate nohighlight">
\[
EPE(X) = \mathbb{E}[(f(X) + \epsilon - \hat{f}(X))^2]
\]</div>
<p><em>Paso 1: Reordenar la expresión</em></p>
<p>Agrupamos los términos para formar una suma:</p>
<p><span class="math notranslate nohighlight">\(
(f(X) + \epsilon - \hat{f}(X)) = (f(X) - \hat{f}(X)) + \epsilon
\)</span></p>
<p>Sustituimos en la expresión original:</p>
<div class="math notranslate nohighlight">
\[
\text{EPE}(X) = \mathbb{E}\left[\left((f(X) - \hat{f}(X)) + \epsilon\right)^2\right]
\]</div>
<p><em>Paso 2: Expandir el cuadrado</em></p>
<p>Aplicamos la identidad algebraica <span class="math notranslate nohighlight">\((a + b)^2 = a^2 + 2ab + b^2\)</span>:</p>
<div class="math notranslate nohighlight">
\[
= \mathbb{E}[(f(X) - \hat{f}(X))^2 + 2(f(X) - \hat{f}(X))\epsilon + \epsilon^2]
\]</div>
<p><em>Paso 3: Linealidad de la esperanza</em></p>
<p>Separando en tres esperanzas:</p>
<div class="math notranslate nohighlight">
\[
= \mathbb{E}[(f(X) - \hat{f}(X))^2] + 2\mathbb{E}[(f(X) - \hat{f}(X))\epsilon] + \mathbb{E}[\epsilon^2]
\]</div>
<p><em>Paso 4: Propiedad del error</em></p>
<p>Asumimos que:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbb{E}[\epsilon] = 0\)</span> (error centrado)</p></li>
<li><p><span class="math notranslate nohighlight">\(\epsilon\)</span> es independiente de <span class="math notranslate nohighlight">\(\hat{f}(X)\)</span>. Bajo esta independencia, la esperanza del producto es el producto de las esperanzas: <span class="math notranslate nohighlight">\(\mathbb{E}[(f(X) - \hat{f}(X)) \cdot \epsilon] = \mathbb{E}[f(X) - \hat{f}(X)] \cdot \mathbb{E}[\epsilon]\)</span></p></li>
</ul>
<p>Entonces el término cruzado se anula:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[(f(X) - \hat{f}(X))\epsilon] = 0
\]</div>
<p>Expandiendo esta expresión:</p>
<div class="math notranslate nohighlight">
\[
EPE(X) = \mathbb{E}[(f(X) - \hat{f}(X))^2] + \mathbb{E}[\epsilon^2]
\]</div>
<p>Esto se puede interpretar como:</p>
<ol class="arabic simple">
<li><p><strong>Error Reducible</strong>: El error debido a la incapacidad del modelo para aprender perfectamente la verdadera función <span class="math notranslate nohighlight">\(f(x)\)</span>. Esto está representado por <span class="math notranslate nohighlight">\(\mathbb{E}[(f(X) - \hat{f}(X))^2]\)</span>.</p></li>
<li><p><strong>Error Irreducible</strong>: El error debido al ruido inherente en los datos, es decir, <span class="math notranslate nohighlight">\(\mathbb{E}[\epsilon^2] = \sigma^2\)</span>, que no se puede reducir, sin importar cuán bien el modelo aprenda la función verdadera.</p></li>
</ol>
<p>Así, el error total es:</p>
<div class="math notranslate nohighlight">
\[
EPE(X) = \underbrace{\mathbb{E}[(f(X) - \hat{f}(X))^2]}_{\text{Error Reducible}} + \underbrace{\sigma^2}_{\text{Error Irreducible}}
\]</div>
</section>
</section>
<section id="inferencia">
<h4><span class="section-number">6.3.1.2. </span>Inferencia<a class="headerlink" href="#inferencia" title="Link to this heading">#</a></h4>
<p>Cuando estamos interesados en entender la asociación entre <span class="math notranslate nohighlight">\(Y\)</span> y <span class="math notranslate nohighlight">\(X_1,X_2,\cdots,X_p\)</span>, la estimación de <span class="math notranslate nohighlight">\(f\)</span>, <span class="math notranslate nohighlight">\(\hat{f}\)</span> no puede ser tratado como una caja negra. Nuestro objetivo no es necesariamente hacer predicciones de <span class="math notranslate nohighlight">\(Y\)</span>, sino que necesitamos tener una forma exacta de <span class="math notranslate nohighlight">\(f\)</span>.</p>
<p>Podemos estar interesados en responder a preguntas como:</p>
<ul class="simple">
<li><p>¿Qué predictores se asocian con la respuesta?</p></li>
<li><p>¿Cuál es la relación entre la respuesta y cada predictor?</p></li>
<li><p>¿Puede la relación entre <span class="math notranslate nohighlight">\(Y\)</span> y cada predictor ser lineal o es más sofisticada?</p></li>
</ul>
<p>Dependiendo de si nuestro objetivo final es predicción, inferencia o una combinación de ambas, pueden ser apropiados distintos métodos para estimar <span class="math notranslate nohighlight">\(f\)</span>.</p>
<p>Por ejemplo, los modelos lineales permiten una inferencia relativamente simple e interpretable, pero pueden no producir predicciones tan precisas como algunos otros enfoques de modelos lineales. Por el contrario, algunos de los enfoques altamente no lineales pueden proporcionar predicciones bastante precisas para <span class="math notranslate nohighlight">\(Y\)</span> , pero esto se produce a expensas de un modelo menos interpretable para el cual la inferencia es más desafiante.</p>
</section>
</section>
<section id="descomposicion-de-sesgo-varianza-del-error-reducible">
<h3><span class="section-number">6.3.2. </span>Descomposición de Sesgo-Varianza (del Error Reducible)<a class="headerlink" href="#descomposicion-de-sesgo-varianza-del-error-reducible" title="Link to this heading">#</a></h3>
<p>El error reducible se puede descomponer aún más en <strong>sesgo</strong> y <strong>varianza</strong>:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[(f(X) - \hat{f}(X))^2] = (\mathbb{E}[\hat{f}(X)] - f(x))^2 + \mathbb{E}[(\hat{f}(X) - \mathbb{E}[\hat{f}(X)])^2]
\]</div>
<p>Donde:</p>
<ul class="simple">
<li><p><strong>Sesgo</strong>: <span class="math notranslate nohighlight">\((\mathbb{E}[\hat{f}(X)] - f(X))^2\)</span> es el error debido a las suposiciones del modelo que le impiden capturar perfectamente la función verdadera. Es decir, <strong>mide cuánto se aleja en promedio tu modelo de la realidad</strong>.</p></li>
<li><p><strong>Varianza</strong>: <span class="math notranslate nohighlight">\(\mathbb{E}[(\hat{f}(X) - \mathbb{E}[\hat{f}(X)])^2]\)</span> es el error debido a la sensibilidad del modelo a diferentes conjuntos de datos de entrenamiento (es decir, cuánto varían las predicciones del modelo). Es decir, <strong>mide cuánto varía tu modelo ante pequeños cambios en los datos de entrenamiento</strong>.</p></li>
</ul>
<p>Así, el error total se puede escribir como:</p>
<div class="math notranslate nohighlight">
\[
EPE(x) = \underbrace{\text{Sesgo}^2 + \text{Varianza}}_{\text{Error Reducible}} + \underbrace{\sigma^2}_{\text{Error Irreducible}}
\]</div>
<p><strong>Para recordar:</strong></p>
<ul>
<li><p><strong>Error Reducible</strong>: Esta es la parte del error que se puede reducir mejorando el modelo (por ejemplo, usando un modelo más complejo, mejor ajuste o más datos). Consiste en <strong>Sesgo</strong> y <strong>Varianza</strong>.</p>
<div class="math notranslate nohighlight">
\[
  \text{Error Reducible} = \text{Sesgo}^2 + \text{Varianza}
  \]</div>
</li>
<li><p><strong>Error Irreducible</strong>: Este es el ruido en los datos, que no se puede eliminar con ningún modelo. Está representado por la varianza del ruido <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
<div class="math notranslate nohighlight">
\[
  \text{Error Irreducible} = \sigma^2
  \]</div>
</li>
</ul>
<p>Por lo tanto, la fórmula general para el error de predicción esperado (error total) es:</p>
<div class="math notranslate nohighlight">
\[
EPE(x) = \text{Sesgo}^2 + \text{Varianza} + \sigma^2
\]</div>
</section>
</section>
<section id="metodos-de-remuestreo">
<h2><span class="section-number">6.4. </span>Métodos de remuestreo<a class="headerlink" href="#metodos-de-remuestreo" title="Link to this heading">#</a></h2>
<p>Los <strong>métodos de remuestreo</strong> son una herramienta indispensable en la estadística moderna. Implican extraer repetidamente muestras de un conjunto de <strong>entrenamiento</strong> y reajustar un modelo de interés en cada muestra para obtener información adicional sobre el modelo ajustado.</p>
<p>Dos métodos más usados en el remuestreo son <em>bootstrap</em> y <em>cross-validation</em>.</p>
<p><strong>Bootstrap</strong></p>
<p>El bootstrap se utiliza en varios contextos, más comúnmente para proporcionar una <strong>medida de precisión</strong> de una estimación de un parámetro o de un método de aprendizaje estadístico dado.</p>
<p><strong>Cross-validation</strong></p>
<p>El proceso de evaluar el desempeño de un modelo se conoce como <strong>evaluación del modelo</strong>, mientras que el proceso de seleccionar el nivel adecuado de flexibilidad para un modelo se conoce como <strong>selección del modelo</strong>.</p>
<section id="bootstrap">
<h3><span class="section-number">6.4.1. </span>Bootstrap<a class="headerlink" href="#bootstrap" title="Link to this heading">#</a></h3>
<p>Supongamos que deseamos obtener el siguiente estimador</p>
<div class="math notranslate nohighlight">
\[
\tau = \frac{\text{median}(x)}{(\text{max}(x)-\text{min}(x))}
\]</div>
<p>Nota que, si el problema fuese estimar el <a class="reference external" href="https://es.wikipedia.org/wiki/Intervalo_de_confianza">intervalo de confianza de la media</a>, tenemos un procedimiento paramétrico para hacerlo (pero también podemos usar bootstrap). Sin embargo, el estimador <span class="math notranslate nohighlight">\(\tau\)</span> no tiene un fórmula específica para estimar los intervalos de confianza, estos son los ejemplos donde bootstrap es más útil.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>  <span class="c1"># Importamos la librería NumPy, útil para cálculos numéricos y manejo de arreglos</span>
<span class="kn">import</span> <span class="nn">random</span>       <span class="c1"># Importamos la librería random del sistema estándar de Python para operaciones aleatorias</span>

<span class="c1"># Creamos un arreglo de NumPy que contiene las edades de una población de 11 individuos</span>
<span class="n">edad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">24</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">26</span><span class="p">,</span><span class="mi">27</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">29</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">31</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">38</span><span class="p">,</span><span class="mi">48</span><span class="p">])</span>

<span class="c1"># Obtenemos la forma (shape) del arreglo &#39;edad&#39;. Esto devuelve una tupla con el número de elementos (en este caso, (11,))</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">edad</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># n[0] será igual a 11, el tamaño de la población</span>

<span class="c1"># Fijamos una semilla para el generador aleatorio de Python. Esto asegura que el muestreo sea reproducible</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">19</span><span class="p">)</span>

<span class="c1"># Creamos un arreglo con los índices (posiciones) de los elementos en &#39;edad&#39;, es decir, de 0 a 10</span>
<span class="n">indice</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># Este arreglo representa los &quot;ID&quot; o posiciones de los individuos en la población</span>

<span class="c1"># Definimos el tamaño de la muestra que queremos tomar. En este caso se seleccionarán 20 elementos</span>
<span class="n">nsam</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># Es mayor al tamaño de la población, pero como se toma con reemplazo, no hay problema</span>

<span class="c1"># Usamos la función random.choices para seleccionar una muestra aleatoria de 20 índices con reemplazo</span>
<span class="n">sam</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choices</span><span class="p">(</span><span class="n">indice</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">nsam</span><span class="p">)</span>  <span class="c1"># Esto permite que un mismo índice pueda ser seleccionado varias veces</span>

<span class="c1"># Calculamos una estadística &#39;tau&#39; sobre la muestra obtenida:</span>
<span class="c1"># - edad[sam] extrae las edades correspondientes a los índices seleccionados</span>
<span class="c1"># - np.median(...) calcula la mediana de esa muestra</span>
<span class="c1"># - np.ptp(...) calcula el rango (máx - mín) de la muestra</span>
<span class="c1"># Finalmente se obtiene el cociente entre mediana y rango como una medida relativa de tendencia central</span>
<span class="n">tau</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">edad</span><span class="p">[</span><span class="n">sam</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">ptp</span><span class="p">(</span><span class="n">edad</span><span class="p">[</span><span class="n">sam</span><span class="p">])</span>

<span class="c1"># Evaluamos &#39;tau&#39;. En un entorno interactivo, esta línea imprime el resultado de la operación anterior</span>
<span class="n">tau</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.125
</pre></div>
</div>
</div>
</div>
<p>Ahora realizamos la estimación <strong>bootstrap</strong> mano</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Definimos una función llamada tau_f que calcula una medida estadística para un arreglo de datos</span>
<span class="k">def</span> <span class="nf">tau_f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c1"># Calcula el cociente entre la mediana del arreglo y su rango (diferencia entre el valor máximo y mínimo)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">ptp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># np.ptp(x) es &quot;peak to peak&quot;: np.max(x) - np.min(x)</span>
    <span class="k">return</span> <span class="n">res</span>  <span class="c1"># Devuelve el valor calculado</span>

<span class="c1"># Definimos el número de repeticiones para el procedimiento de bootstrap</span>
<span class="n">nboot</span> <span class="o">=</span> <span class="mi">9999</span>  <span class="c1"># Realizaremos 9999 remuestreos para aproximar la distribución empírica de tau</span>

<span class="c1"># Creamos una lista vacía para almacenar los valores de tau generados en cada iteración</span>
<span class="n">tau_sol</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Ejecutamos un ciclo de remuestreo con reemplazo</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nboot</span><span class="p">):</span>
    <span class="c1"># Seleccionamos aleatoriamente &#39;nsam&#39; índices con reemplazo desde los índices de la población</span>
    <span class="n">sam</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choices</span><span class="p">(</span><span class="n">indice</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">nsam</span><span class="p">)</span>
    
    <span class="c1"># Calculamos el valor de tau para la muestra seleccionada usando la función definida</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="n">tau_f</span><span class="p">(</span><span class="n">edad</span><span class="p">[</span><span class="n">sam</span><span class="p">])</span>
    
    <span class="c1"># Agregamos el resultado a la lista de valores tau</span>
    <span class="n">tau_sol</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>

<span class="c1"># Importamos la biblioteca seaborn para visualización estadística</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="c1"># Graficamos un histograma de la distribución de valores tau obtenidos a partir del bootstrap</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">tau_sol</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: ylabel=&#39;Count&#39;&gt;
</pre></div>
</div>
<img alt="_images/363739b873b068cbba9889635b367552fb3dd7dd28aee95f11dfbdc0d5ced5f1.png" src="_images/363739b873b068cbba9889635b367552fb3dd7dd28aee95f11dfbdc0d5ced5f1.png" />
</div>
</div>
<p>Ahora usamos el método <code class="docutils literal notranslate"><span class="pre">bootstrap</span></code> de la librería <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">bootstrap</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">bootstrap</span><span class="p">((</span><span class="n">edad</span><span class="p">,),</span> <span class="n">tau_f</span><span class="p">,</span> <span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="n">res</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">bootstrap_distribution</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: ylabel=&#39;Count&#39;&gt;
</pre></div>
</div>
<img alt="_images/4ccc52650c2ddfcef2276b0604ee7ca58220721658f908dece6966b23146bab5.png" src="_images/4ccc52650c2ddfcef2276b0604ee7ca58220721658f908dece6966b23146bab5.png" />
</div>
</div>
</section>
</section>
<section id="cross-validation">
<h2><span class="section-number">6.5. </span>Cross-validation<a class="headerlink" href="#cross-validation" title="Link to this heading">#</a></h2>
<p><strong>¿Qué ocurre en la validación cruzada?</strong></p>
<p>En la validación cruzada (cross-validation, CV), el objetivo es estimar <strong>el desempeño esperado del modelo</strong> en datos no vistos. La lógica general es:</p>
<ol class="arabic simple">
<li><p>Divides tus datos en <code class="docutils literal notranslate"><span class="pre">k</span></code> folds.</p></li>
<li><p>Para cada fold:</p>
<ul class="simple">
<li><p>Entrenas el modelo <strong>desde cero</strong> en <code class="docutils literal notranslate"><span class="pre">k-1</span></code> folds (conjunto de entrenamiento).</p></li>
<li><p>Evalúas el modelo en el fold restante (conjunto de validación).</p></li>
</ul>
</li>
<li><p>Repites este proceso <code class="docutils literal notranslate"><span class="pre">k</span></code> veces y promedias las métricas.</p></li>
</ol>
<p><strong>Entonces… ¿cómo se fijan los parámetros?</strong></p>
<p>Hay dos tipos de parámetros que debes distinguir:</p>
<section id="parametros-del-modelo-entrenables">
<h3><span class="section-number">6.5.1. </span>1. Parámetros del modelo (entrenables)<a class="headerlink" href="#parametros-del-modelo-entrenables" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Se ajustan automáticamente durante el entrenamiento en cada fold.</p></li>
<li><p>Ejemplos: coeficientes en regresión, pesos de red neuronal.</p></li>
</ul>
</section>
<section id="hiperparametros-no-entrenables">
<h3><span class="section-number">6.5.2. </span>2. Hiperparámetros (no entrenables)<a class="headerlink" href="#hiperparametros-no-entrenables" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Se definen <strong>antes</strong> del entrenamiento y afectan cómo el modelo se entrena.</p></li>
<li><p>Ejemplos: número de árboles en un Random Forest, <code class="docutils literal notranslate"><span class="pre">C</span></code> o <code class="docutils literal notranslate"><span class="pre">gamma</span></code> en un SVM.</p></li>
</ul>
<blockquote>
<div><p><strong>Importante:</strong> Los hiperparámetros no deben fijarse usando todos los datos antes de hacer CV.</p>
</div></blockquote>
<p><strong>¿Cómo se seleccionan los hiperparámetros?</strong></p>
<p>Mediante <strong>validación cruzada anidada (nested CV)</strong> o una <strong>búsqueda de hiperparámetros dentro del CV</strong>:</p>
<p><strong>Búsqueda de hiperparámetros dentro de la CV</strong></p>
<ul class="simple">
<li><p>Dentro de cada entrenamiento (en <code class="docutils literal notranslate"><span class="pre">k-1</span></code> folds), haces búsqueda (por ejemplo, grid search o random search).</p></li>
<li><p>Seleccionas los mejores hiperparámetros <strong>dentro del fold</strong>.</p></li>
<li><p>Evalúas ese modelo en el fold restante.</p></li>
</ul>
<p><strong>¿Cuándo fijar el modelo final?</strong></p>
<p>Después de hacer CV:</p>
<ol class="arabic simple">
<li><p>Eliges los hiperparámetros que dieron <strong>mejor desempeño promedio</strong>.</p></li>
<li><p>Entrenas el <strong>modelo final</strong> con esos hiperparámetros sobre <strong>todos los datos disponibles</strong>.</p></li>
<li><p>Este es el modelo que puedes usar para predicción o producción.</p></li>
</ol>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Etapa</p></th>
<th class="head"><p>Acción</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Antes de CV</p></td>
<td><p>No fijar hiperparámetros aún</p></td>
</tr>
<tr class="row-odd"><td><p>Dentro de CV</p></td>
<td><p>Buscar hiperparámetros óptimos usando solo datos de entrenamiento</p></td>
</tr>
<tr class="row-even"><td><p>Después de CV</p></td>
<td><p>Entrenar modelo final con mejores hiperparámetros usando todos los datos</p></td>
</tr>
</tbody>
</table>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importamos los módulos necesarios</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>  <span class="c1"># Dataset de ejemplo</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">StratifiedKFold</span>  <span class="c1"># Validación cruzada y búsqueda de hiperparámetros</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>  <span class="c1"># Modelo de árbol de decisión</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>  <span class="c1"># Para encadenar preprocesamiento + modelo</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>  <span class="c1"># Escalado de variables (opcional para árboles)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>  <span class="c1"># Operaciones numéricas</span>

<span class="c1"># 1. Cargamos los datos</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># X: características, y: etiquetas</span>

<span class="c1"># 2. Definimos un pipeline de procesamiento: escalado (aunque no es necesario para árboles) + modelo</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>  <span class="c1"># Escalado opcional, útil si luego cambiamos el modelo</span>
    <span class="p">(</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>  <span class="c1"># Modelo de árbol con semilla fija</span>
<span class="p">])</span>

<span class="c1"># 3. Definimos la grilla de hiperparámetros a buscar para el árbol de decisión</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;clf__max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>  <span class="c1"># Profundidad máxima del árbol</span>
    <span class="s1">&#39;clf__min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>  <span class="c1"># Mínimo de muestras para dividir un nodo</span>
    <span class="s1">&#39;clf__criterion&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="s1">&#39;entropy&#39;</span><span class="p">]</span>  <span class="c1"># Función de impureza: Gini o entropía</span>
<span class="p">}</span>

<span class="c1"># 4. Definimos la estrategia de validación cruzada externa (5 folds estratificados)</span>
<span class="n">cv_outer</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 5. Creamos el objeto de búsqueda de hiperparámetros con validación cruzada interna (3 folds)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">pipe</span><span class="p">,</span>       <span class="c1"># Pipeline a evaluar</span>
                   <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span>  <span class="c1"># Grilla de hiperparámetros</span>
                   <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>                   <span class="c1"># Validación cruzada interna</span>
                   <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span>     <span class="c1"># Métrica de evaluación</span>
                   <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>              <span class="c1"># Usar todos los núcleos disponibles</span>

<span class="c1"># 6. Evaluamos el modelo con validación cruzada externa</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv_outer</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>  <span class="c1"># Se entrena y evalúa en cada fold externo</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Puntajes por fold:&quot;</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>  <span class="c1"># Precisión en cada fold</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Precisión promedio:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>  <span class="c1"># Precisión promedio como estimación del desempeño general</span>

<span class="c1"># 7. Entrenamos el modelo final con todos los datos usando los mejores hiperparámetros encontrados</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejores hiperparámetros encontrados:&quot;</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>

<span class="c1"># 8. Obtenemos el modelo final completamente entrenado</span>
<span class="n">modelo_final</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">best_estimator_</span>  <span class="c1"># Este es el modelo listo para usar en producción</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Puntajes por fold: [0.96666667 0.96666667 0.93333333 0.96666667 0.9       ]
Precisión promedio: 0.9466666666666667
Mejores hiperparámetros encontrados: {&#39;clf__criterion&#39;: &#39;gini&#39;, &#39;clf__max_depth&#39;: 3, &#39;clf__min_samples_split&#39;: 2}
</pre></div>
</div>
</div>
</div>
<p>Ahora miramos los resultados del proceso de manera gráfica:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">folds</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;Fold </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">scores</span><span class="p">))]</span>  <span class="c1"># Etiquetas: Fold 1, Fold 2, ...</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">folds</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">scores</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Precisión por fold (CV externa)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Fold&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Precisión&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Escala de precisión entre 0 y 1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a506e972d0e8a2be466a117b565212ec8d44e1a8603c160c04db07717e5e57de.png" src="_images/a506e972d0e8a2be466a117b565212ec8d44e1a8603c160c04db07717e5e57de.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="c1"># Convierte los resultados a DataFrame y agrega una columna legible de parámetros</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">results</span><span class="p">[</span><span class="s1">&#39;params_str&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>

<span class="c1"># Identificar columnas de los folds internos</span>
<span class="n">fold_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">col</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;split&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">col</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_test_score&#39;</span><span class="p">)]</span>

<span class="c1"># Reestructurar el DataFrame para tener una fila por fold y configuración</span>
<span class="n">results_long</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span>
    <span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;params_str&#39;</span><span class="p">],</span>
    <span class="n">value_vars</span><span class="o">=</span><span class="n">fold_columns</span><span class="p">,</span>
    <span class="n">var_name</span><span class="o">=</span><span class="s1">&#39;Fold&#39;</span><span class="p">,</span>
    <span class="n">value_name</span><span class="o">=</span><span class="s1">&#39;Score&#39;</span>
<span class="p">)</span>

<span class="c1"># Limpiar nombre del fold: de &#39;split0_test_score&#39; → &#39;Fold 1&#39;</span>
<span class="n">results_long</span><span class="p">[</span><span class="s1">&#39;Fold&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">results_long</span><span class="p">[</span><span class="s1">&#39;Fold&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;split(\d+)_&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">results_long</span><span class="p">[</span><span class="s1">&#39;Fold&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;Fold &#39;</span> <span class="o">+</span> <span class="n">results_long</span><span class="p">[</span><span class="s1">&#39;Fold&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>

<span class="c1"># Ordenar configuraciones por media de Score (para mejor visualización)</span>
<span class="n">order</span> <span class="o">=</span> <span class="n">results_long</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;params_str&#39;</span><span class="p">)[</span><span class="s1">&#39;Score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">index</span>

<span class="c1"># Mostrar tabla con los datos a graficar</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Resultados detallados por fold:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results_long</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results_long</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Resultados detallados por fold:

                                           params_str    Fold  Score
0   {&#39;clf__criterion&#39;: &#39;gini&#39;, &#39;clf__max_depth&#39;: 2...  Fold 1   0.96
1   {&#39;clf__criterion&#39;: &#39;gini&#39;, &#39;clf__max_depth&#39;: 2...  Fold 1   0.96
2   {&#39;clf__criterion&#39;: &#39;gini&#39;, &#39;clf__max_depth&#39;: 2...  Fold 1   0.96
3   {&#39;clf__criterion&#39;: &#39;gini&#39;, &#39;clf__max_depth&#39;: 3...  Fold 1   0.98
4   {&#39;clf__criterion&#39;: &#39;gini&#39;, &#39;clf__max_depth&#39;: 3...  Fold 1   0.98
..                                                ...     ...    ...
67  {&#39;clf__criterion&#39;: &#39;entropy&#39;, &#39;clf__max_depth&#39;...  Fold 3   0.96
68  {&#39;clf__criterion&#39;: &#39;entropy&#39;, &#39;clf__max_depth&#39;...  Fold 3   0.96
69  {&#39;clf__criterion&#39;: &#39;entropy&#39;, &#39;clf__max_depth&#39;...  Fold 3   0.96
70  {&#39;clf__criterion&#39;: &#39;entropy&#39;, &#39;clf__max_depth&#39;...  Fold 3   0.96
71  {&#39;clf__criterion&#39;: &#39;entropy&#39;, &#39;clf__max_depth&#39;...  Fold 3   0.96

[72 rows x 3 columns]
(72, 3)
</pre></div>
</div>
</div>
</div>
<p>Nota que <code class="docutils literal notranslate"><span class="pre">results_long</span></code> tiene 72 filas, ¿por qué?</p>
<p>La estructura del DataFrame <code class="docutils literal notranslate"><span class="pre">results_long</span></code> resulta de la combinación entre:</p>
<ul class="simple">
<li><p>El número de <strong>combinaciones de hiperparámetros evaluadas</strong></p></li>
<li><p>El número de <strong>folds internos</strong> utilizados por <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code></p></li>
</ul>
<p><strong>Supuestos del ejemplo</strong></p>
<p>Se definió la grilla de hiperparámetros de la siguiente forma:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;clf__criterion&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="s1">&#39;entropy&#39;</span><span class="p">],</span>            <span class="c1"># 2 opciones</span>
    <span class="s1">&#39;clf__max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>                   <span class="c1"># 4 opciones</span>
    <span class="s1">&#39;clf__min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>               <span class="c1"># 3 opciones</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Esto da lugar a un total de combinaciones de hiperparámetros:</p>
<p><span class="math notranslate nohighlight">\(2 * 4 * 3 = 24\)</span> combinaciones</p>
<p>Y si GridSearchCV se ejecuta con cv=3, significa que para cada combinación de hiperparámetros, se realiza una validación cruzada interna de 3 folds.</p>
<p>El número total de filas de results_long es:</p>
<p><span class="math notranslate nohighlight">\(24\)</span> combinaciones * <span class="math notranslate nohighlight">\(3\)</span> folds <span class="math notranslate nohighlight">\(= 72\)</span> filas</p>
<p>Esto es exactamente lo que se espera cuando usamos GridSearchCV con <code class="docutils literal notranslate"><span class="pre">cv=3</span></code> y una malla con 24 combinaciones distintas de hiperparámetros.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar resultados por fold para todas las configuraciones</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;params_str&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Score&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;Fold&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">results_long</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Configuración de hiperparámetros&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Precisión por fold&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Resultados detallados por fold para todas las configuraciones (GridSearchCV)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Fold&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.02</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/fb0a92d38215976e224f94ab627dc4a7570b9f8029f843d462c98db49e62d9a0.png" src="_images/fb0a92d38215976e224f94ab627dc4a7570b9f8029f843d462c98db49e62d9a0.png" />
</div>
</div>
</section>
</section>
<section id="ejercicios">
<h2><span class="section-number">6.6. </span>Ejercicios<a class="headerlink" href="#ejercicios" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Supón que tienes un conjunto de datos reales <span class="math notranslate nohighlight">\((X, y)\)</span> y un modelo de aprendizaje supervisado.</p></li>
</ol>
<p><strong>Paso 1: Realiza validación cruzada</strong></p>
<p>Haz <code class="docutils literal notranslate"><span class="pre">K-Fold</span> <span class="pre">Cross</span> <span class="pre">Validation</span></code> (por ejemplo, con 5 o 10 folds) para obtener predicciones en los <strong>datos de test de cada fold</strong>.</p>
<p><strong>Paso 2: Calcula predicciones promedio</strong></p>
<p>Para cada observación <span class="math notranslate nohighlight">\( x_i \)</span>, obtén varias predicciones del modelo (una por cada fold en que fue parte del conjunto de test). Calcula:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( \hat{f}(x_i) \)</span>: promedio de las predicciones del modelo para <span class="math notranslate nohighlight">\( x_i \)</span></p></li>
<li><p><span class="math notranslate nohighlight">\( y_i \)</span>: valor real observado</p></li>
</ul>
<p><strong>Paso 3: Calcula estimaciones de sesgo y varianza</strong></p>
<p>Para cada observación <span class="math notranslate nohighlight">\( x_i \)</span>:</p>
<ul class="simple">
<li><p><strong>Sesgo</strong>: <span class="math notranslate nohighlight">\( \text{Sesgo}(x_i) = \hat{f}(x_i) - y_i \)</span></p></li>
<li><p><strong>Sesgo²</strong>: <span class="math notranslate nohighlight">\( (\hat{f}(x_i) - y_i)^2 \)</span></p></li>
<li><p><strong>Varianza</strong>: varianza de las predicciones del modelo sobre <span class="math notranslate nohighlight">\( x_i \)</span></p></li>
</ul>
<p>Promedia sobre todos los <span class="math notranslate nohighlight">\( x_i \)</span>:</p>
<div class="math notranslate nohighlight">
\[
\text{Sesgo}^2_{\text{prom}} = \frac{1}{n} \sum_{i=1}^n \left( \hat{f}(x_i) - y_i \right)^2
\]</div>
<div class="math notranslate nohighlight">
\[
\text{Varianza}_{\text{prom}} = \frac{1}{n} \sum_{i=1}^n \text{Var}_{k}\left( \hat{f}_k(x_i) \right)
\]</div>
<p><strong>Nota</strong></p>
<ul class="simple">
<li><p>Estos cálculos <strong>requieren guardar todas las predicciones por fold para cada muestra</strong>.</p></li>
<li><p>La estimación del <strong>error irreducible</strong> no es posible directamente a partir de los datos observados. Puedes asumir que forma parte del error total y restarla del EPE estimado si conoces el sesgo y la varianza.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "conda-base-py"
        },
        kernelOptions: {
            name: "conda-base-py",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'conda-base-py'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="PruebasHipotesis.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">5. </span>Pruebas de Hipótesis</p>
      </div>
    </a>
    <a class="right-next"
       href="AprendizajeSupervisado.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">7. </span>Aprendizaje Supervisado</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#el-bosque-inteligencia-artificial">6.1. El bosque: Inteligencia Artificial</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">6.2. Machine Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#terminologia">6.2.1. Terminología</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aprendizaje-supervisado">6.3. Aprendizaje Supervisado</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimar-f">6.3.1. Estimar <span class="math notranslate nohighlight">\(f\)</span></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#prediccion">6.3.1.1. Predicción</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#error-total">6.3.1.1.1. Error Total</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#inferencia">6.3.1.2. Inferencia</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#descomposicion-de-sesgo-varianza-del-error-reducible">6.3.2. Descomposición de Sesgo-Varianza (del Error Reducible)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metodos-de-remuestreo">6.4. Métodos de remuestreo</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bootstrap">6.4.1. Bootstrap</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation">6.5. Cross-validation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parametros-del-modelo-entrenables">6.5.1. 1. Parámetros del modelo (entrenables)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hiperparametros-no-entrenables">6.5.2. 2. Hiperparámetros (no entrenables)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ejercicios">6.6. Ejercicios</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Víctor Morales Oñate
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>