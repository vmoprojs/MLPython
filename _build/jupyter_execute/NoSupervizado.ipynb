{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un clúster es una agrupación de objetos que comparten similitudes, y los objetos que pertenecen a diferentes clústeres presentan diferencias. Encontrar grupos en los datos es el objetivo principal de la agrupación en clústeres. \n",
    "\n",
    "> El objetivo es minimizar las diferencias dentro de cada grupo y maximizar las diferencias entre los clústeres.\n",
    "\n",
    "La agrupación en clústeres consiste en dividir un conjunto de datos finito sin etiquetar en subconuntos de datos diferenciados que emergen de estreucturas subyacentes en los datos.\n",
    "\n",
    "Sea \n",
    "\n",
    "$$\n",
    "\\mathbf{X}= \\{\\mathbf{x}_1,\\mathbf{x}_2,\\ldots,\\mathbf{x}_i,\\ldots,\\mathbf{x}_N\\}\n",
    "$$\n",
    "\n",
    "un conjunto de objetos de entrada donde $\\mathbf{x}_i = \\left(x_{i1},x_{i2},\\ldots,x_{ij},\\ldots,x_{id}\\right) \\in \\mathbb{R}^d$, y  $x_{ij}$  es una característica (atributo, dimensión o variable). Una partición $K$ de $\\mathbf{X}$, $C = \\{C_1,\\ldots,C_K\\}$ ($K\\leq N$) es una partición dura si:\n",
    "\n",
    "\n",
    "- Cada clúster debe tener al menos un elemento: $C_i\\neq \\emptyset$, $i=1,\\ldots,K$. \n",
    "- La unión de todos los clústers es el conjunto de entrada $\\mathbf{X}$: $\\bigcup_{i=1}^KC_i=\\mathbf{X}$. \n",
    "- Si un objeto pertenece a un cluster, no puede pertenecer a otro cluster: $C_i\\cap C_j = \\emptyset$, $i,j=1,\\ldots,K$ and $i\\neq j$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means\n",
    "\n",
    "> El algoritmo k-means es quizás el método de agrupación más utilizado. Después de haber sido estudiado durante varias décadas, sirve como base para muchas técnicas de agrupación más sofisticadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo \n",
    "\n",
    "Veamos un ejemplo de k-means mediante la generación de clústers aleatorios (`make_blobs`) y `k=3`.\n",
    "\n",
    "**Preámbulo y datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_blobs\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshared_utilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_labelled_scatter\n\u001b[1;32m     11\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_blobs(random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     13\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m,n_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Consultorias&Cursos/CURSOS/Cooking/MLPython/pyML/shared_utilities.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m neighbors\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpatches\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgraphviz\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export_graphviz\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpatches\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "\n",
    "#%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from shared_utilities import plot_labelled_scatter\n",
    "\n",
    "X, y = make_blobs(random_state = 10)\n",
    "\n",
    "kmeans = KMeans(n_init = 3,n_clusters = 3)\n",
    "kmeans.fit(X)\n",
    "\n",
    "plot_labelled_scatter(X, kmeans.labels_, ['Cluster 1', 'Cluster 2', 'Cluster 3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algoritmo**\n",
    "\n",
    "**Entradas:** \n",
    "   - Conjunto de patrones en $\\mathbb{R}^n$.\n",
    "   - $k$ número de grupos a formar.\n",
    "\n",
    "**Salidas:** \n",
    "\n",
    "   - Una partición del espacio de patrones, tal que, optimiza la varianza global.\n",
    "\n",
    "**Inicio:** \n",
    "\n",
    "Asignar aleatoreamente un número, del 1 a $K$ a cada observación. Estos funcionan como asignaciones iniciales para las observaciones.\n",
    "\n",
    "**Repetición**\n",
    "\n",
    "  1. Para cada uno de los K conglomerados, calcular el centroide del conglomerado. El k-ésimo centroide del grupo es el vector de las $p$ medias de características para las observaciones en el k-ésimo grupo.\n",
    "  2. Asignar cada observación al conglomerado cuyo centroide es el más cercano (donde más cercano se define utilizando la distancia euclidiana).\n",
    "  \n",
    "**Hasta** La última partición obtenida, (idéntica a la de la iteración\n",
    "anterior ) es la respuesta final del algoritmo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: clasificación de frutas\n",
    "Ejemplo que muestra k-medias para encontrar 4 conglomerados en el conjunto de datos de frutas. Tenga en cuenta que, en general, es importante escalar las características individuales antes de aplicar la agrupación en clústeres de k-medias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from shared_utilities import plot_labelled_scatter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "uu = 'https://raw.githubusercontent.com/vmoprojs/DataLectures/refs/heads/master/fruit_data_with_colors.txt'\n",
    "fruits = pd.read_table(uu)\n",
    "X_fruits = fruits[['mass','width','height', 'color_score']].to_numpy()\n",
    "y_fruits = fruits[['fruit_label']] - 1\n",
    "\n",
    "X_fruits_normalized = MinMaxScaler().fit(X_fruits).transform(X_fruits)  \n",
    "\n",
    "kmeans = KMeans(n_init = 4, random_state = 0,n_clusters = 4)\n",
    "kmeans.fit(X_fruits_normalized)\n",
    "\n",
    "plot_labelled_scatter(X_fruits_normalized, kmeans.labels_, \n",
    "                      ['Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn-extra.readthedocs.io/en/latest/index.html\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "kmedoides = KMedoids(n_clusters = 4, random_state = 0)\n",
    "kmedoides.fit(X_fruits_normalized)\n",
    "\n",
    "plot_labelled_scatter(X_fruits_normalized, kmedoides.labels_, \n",
    "                      ['Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Jerárquico: Aglomerativo\n",
    "\n",
    "Una desventaja potencial del agrupamiento K-medias es que requiere que **especifiquemos previamente** el número de agrupamientos K. \n",
    "\n",
    "El agrupamiento jerárquico es un enfoque alternativo que **no requiere** que nos comprometamos con una elección particular de K. \n",
    "\n",
    "El agrupamiento jerárquico tiene una ventaja adicional sobre el agrupamiento K-medias, ya que da como resultado una atractiva representación basada en árboles de las observaciones, llamada **dendrograma**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algoritmo**\n",
    "\n",
    "**Entradas:** \n",
    "   - Conjunto de patrones en cualquier espacio.\n",
    "\n",
    "**Salidas:** \n",
    "\n",
    "   - Dendograma de agrupamiento\n",
    "\n",
    "**Inicio:** \n",
    "\n",
    "   - Seleccionar una función de comparación entre patrones.\n",
    "   - Calcular la Matriz Global de Semejanza/Diferencia entre grupos.\n",
    "\n",
    "   \n",
    "      \n",
    "\n",
    "**Repetición**\n",
    "\n",
    "   1. Identificar la menor diferencia entre grupos y fusionar dichos grupos en un nuevo grupo con etiqueta única.\n",
    "   2. Actualizar la matriz de sem/dif, eliminando el renglón y columna de los grupos fusionados y agregando un nuevo renglón y columna para el nuevo grupo\n",
    "   3. Registrar la fusión realizada en el dendrograma\n",
    "  \n",
    "**Hasta** Terminar cuando todos los patrones se encuentren agrupados en un solo grupo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Python, el método [AgglomerativeClustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html) nos permite ejecutar clustering jerárquico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from shared_utilities import plot_labelled_scatter\n",
    "\n",
    "X, y = make_blobs(random_state = 10)\n",
    "\n",
    "cls = AgglomerativeClustering(n_clusters = 3)\n",
    "cls_assignment = cls.fit_predict(X)\n",
    "\n",
    "plot_labelled_scatter(X, cls_assignment, \n",
    "        ['Cluster 1', 'Cluster 2', 'Cluster 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(random_state = 10, n_samples = 10)\n",
    "plot_labelled_scatter(X, y, \n",
    "        ['Cluster 1', 'Cluster 2', 'Cluster 3'])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creamos el dendograma**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram,linkage\n",
    "plt.figure()\n",
    "dendrogram(linkage(X, 'complete'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Cada hoja del dendrograma representa una de las $n$ observaciones.\n",
    "\n",
    "-   A medida que subimos por el árbol, algunas hojas comienzan a *fusionarse* en ramas. Estos corresponden a observaciones que son similares entre sí.\n",
    "\n",
    "-   Cuanto antes (más abajo en el árbol) se produzcan fusiones, más similares serán los grupos de observaciones entre sí. Por otro lado, las observaciones que se fusionan más tarde (cerca de la parte superior del árbol) pueden ser bastante diferentes.\n",
    "\n",
    "\n",
    "-   La altura de esta fusión, medida en el eje vertical, **indica cuán diferentes son las dos observaciones**. Por lo tanto, las observaciones que se fusionan en la parte inferior del árbol son bastante similares entre sí, mientras que las observaciones que se fusionan cerca de la parte superior del árbol tenderán a ser bastante diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones para fusionar grupos\n",
    "\n",
    "<img src=\"images/10_fig1.png\" width=\"500\" height=\"300\">\n",
    "\n",
    "-   *Complete*: Disimilitud máxima entre conglomerados. Calcule todas las diferencias por pares entre las observaciones en el grupo $A$ y las observaciones en el grupo $B$, y **registre la mayor de estas diferencias**.\n",
    "\n",
    "-   *Single*: Disimilitud mínima entre conglomerados. Calcule todas las diferencias por pares entre las observaciones en el grupo $A$ y las observaciones en el grupo $B$, y **registre la más pequeña de estas diferencias**. El enlace único puede dar como resultado conglomerados extendidos y finales en los que las observaciones individuales se fusionan una a la vez.\n",
    "\n",
    "-   *Average*: Diferencia media entre grupos. Calcule todas las diferencias por pares entre las observaciones en el grupo $A$ y las observaciones en el grupo $B$, y **registre el promedio de estas diferencias**.\n",
    "\n",
    "-   *Centroid*: Disimilitud entre el centroide para el grupo $A$ (un vector de medias de longitud $p$) y el centroide para el grupo $B$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En **Python** usamos los métodos:\n",
    "\n",
    "- [dendrogram](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html): para elaborar el dendograma.\n",
    "\n",
    "- [linkage](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html): Realiza agrupamiento jerárquico/aglomerativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Linkage: Complete')\n",
    "dendrogram(linkage(X, 'complete'))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Linkage: Single')\n",
    "dendrogram(linkage(X, 'single'))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Linkage: Average')\n",
    "dendrogram(linkage(X, 'average'))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Linkage: Centroid')\n",
    "dendrogram(linkage(X, 'centroid'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un algoritmo no supervisado que tienen por objetivo descubrir grupos a partir de formas arbitrarias de cualquier conjunto de datos y al mismo tiempo puede distinguir *noise points* que no forman parte de ningún grupo.\n",
    "\n",
    "**Parámetros**\n",
    "\n",
    "- Epsilon ($\\epsilon$): define el radio de una *bola*.\n",
    "- MinPts: Número mínimo de puntos requeridos dentro de la bola de radio $\\epsilon$\n",
    "\n",
    "**Definiciones**:\n",
    "\n",
    "-  Bola Cerrada: $B_{\\epsilon}(p)=B(p;\\epsilon)=\\{x\\in X\\mid d(x,p)\\leq \\epsilon\\}$, donde $p$ es el centro y $\\epsilon$ es el radio\n",
    "-  *Core point*: Si, dentro de la bola, contiene un número de puntos mayor o igual a *MinPts*\n",
    "-  *Border point*: Si, dentro de la bola, contiene al menos un *core point*\n",
    "-  *Noise point*: Si, dentro de la bola, no contiene ningún *core point*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/dbscan.jpg\" width=\"500\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Python:\n",
    "\n",
    "- [`DBSCAN`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html) es el método para ejecutar el algortimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(random_state = 9, n_samples = 25)\n",
    "\n",
    "dbscan = DBSCAN(eps = 2, min_samples = 2)\n",
    "\n",
    "cls = dbscan.fit_predict(X)\n",
    "print(\"Cluster membership values:\\n{}\".format(cls))\n",
    "\n",
    "plot_labelled_scatter(X, cls + 1, \n",
    "        ['Noise', 'Cluster 0', 'Cluster 1', 'Cluster 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: clasificación de clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu = \"https://raw.githubusercontent.com/vmoprojs/DataLectures/master/Mall_Customers.csv\"\n",
    "datos = pd.read_csv(uu)\n",
    "\n",
    "\n",
    "dbDat = datos.iloc[:,3:5]\n",
    "dbDat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(dbDat.AnnualIncome,dbDat.SpendingScore)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "dd = pd.DataFrame(distance_matrix(dbDat.values, dbDat.values), index=dbDat.index, columns=dbDat.index)\n",
    "n = len(np.sort(dd.values))\n",
    "dd = np.sort(dd.values[np.triu_indices(n, k = 1)])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dd)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps = 10, min_samples = 3)\n",
    "\n",
    "cls = dbscan.fit_predict(dbDat)\n",
    "print(\"Cluster membership values:\\n{}\".format(cls))\n",
    "\n",
    "plot_labelled_scatter(dbDat.values, cls + 1, \n",
    "        ['Noise', 'Cluster 0', 'Cluster 1', 'Cluster 2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Un ejemplo combinado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "www = \"https://stat.ethz.ch/Teaching/Datasets/WBL/crime2.dat\"\n",
    "crime = pd.read_csv(www,sep=\" \")\n",
    "crime.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Antes de aplicar ACP, cada variable debe ser centrada y de varianza igual a 1\n",
    "X_normalized = StandardScaler().fit(crime).transform(crime) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2).fit(X_normalized)\n",
    "\n",
    "X_pca = pca.transform(X_normalized) # nuevos componentes\n",
    "print('varianza explicada',pca.explained_variance_ratio_) # vaianza explicada\n",
    "\n",
    "grupos = KMeans(n_clusters = 3)\n",
    "grupos.fit(X_pca)\n",
    "\n",
    "plot_labelled_scatter(X_pca, grupos.labels_, ['Cluster 1', 'Cluster 2', 'Cluster 3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps = 0.8, min_samples = 3)\n",
    "\n",
    "cls = dbscan.fit_predict(X_pca)\n",
    "print(np.unique(cls))\n",
    "plot_labelled_scatter(X_pca, cls + 1, \n",
    "        ['Noise', 'Cluster 0', 'Cluster 1', 'Cluster 2'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-base-py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}